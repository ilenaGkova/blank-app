from mongo_connection import User, Status, Question_Questionnaire, Question, Favorite_Recommendation, \
    Removed_Recommendation, Recommendation, Recommendation_Per_Person
from check_and_balance import get_status
from generate_items import generate_recommendation_id, calculate_fail_count
from add_data_in_collection import add_recommendation
from generate_recommendations_functions import enter_recommendation_for_user, generate_valid_index
from initialise_variables import con_question, min_time_limit, max_limit
from langchain.schema import HumanMessage, SystemMessage
from langchain.chat_models import init_chat_model
import streamlit as st
import re
import os
import requests
import json

active_model = st.secrets["API"]["active_model"]  # Find active model in secrets


# This function generates a required amount of recommendations by setting a prompt in an openAI machine
def generate_recommendations_by_AI(passcode, entries_generated_by_AI):
    index = 0  # Set to the index to indicate we added a recommendation to the user to keep track of how many

    while index < entries_generated_by_AI:

        outcome, new_recommendation, prompt = return_prompt(passcode)

        fail_count = 0  # We have a minor fail count to keep track if the recommendation was added, we probably won't have to use it unless we have various users doing this at the same time

        recommendation_added = False

        if outcome:  # Add recommendation only of one was generated

            title, description, duration = extract_json(new_recommendation, create_prompt(passcode))

            while fail_count <= calculate_fail_count() and not recommendation_added:  # We have a maximum of 100 attempts to enter the recommendations

                recommendation_generated_id = generate_recommendation_id()  # Generate an ID for a new recommendation in the Recommendation collection, this means that future users will be able to see this generated recommendation

                recommendation_added, recommendation_added_message = add_recommendation(recommendation_generated_id,
                                                                                        active_model,
                                                                                        title, description, None,
                                                                                        duration * 2,
                                                                                        duration, prompt, new_recommendation)  # We enter OpenAI as the passcode of the creator

                if recommendation_added:

                    enter_recommendation_for_user(passcode, recommendation_generated_id, fail_count,
                                                  'A')  # Add the recommendation with Category A, aka generated by OpenAI

                else:

                    fail_count += 1  # Increase the minor fail count

        if not recommendation_added:
            enter_recommendation_for_user(passcode, generate_valid_index(), fail_count,
                                          'A-')  # Add the recommendation with Category A-, aka chosen by algorithm when is should have been generated by OpenAI

        index += 1  # Increase to the index to indicate we added a recommendation to the user to keep track of how many

    return index


# This function returns the prompt to run through the LLM
def create_prompt(passcode):
    return (
        f"We have a user in an application. We require one (1) recommendation for the user to release stress today. "
        f"We have information on the user following:"
        f"\n----------------\n"
        f"{generate_user_profile(passcode)}"  # This function creates the user's profile
        f"\n----------------\n"
        f"Please return your  answer exclusively in one (1) JSON request containing a title, a description and a duration between {min_time_limit} - {max_limit} minutes."
        f"A sample answer would look like this:\n"
        f"{{\n"
        f'    "Title": "This is a title",\n'
        f'    "Description": "This is a description",\n'
        f'    "Duration": 10\n'
        f"}}"

    )


def call_gemini_api(passcode):
    url = st.secrets["API"]["geminikey"]  # Find gemini key (as URL) in secret file
    headers = {
        "Content-Type": "application/json",
    }

    data = {
        "contents": [
            {
                "parts": [
                    {
                        "text": create_prompt(passcode)  # Get prompt to submit
                    }
                ]
            }
        ]
    }

    response = requests.post(url, headers=headers, data=json.dumps(data))
    if response.status_code == 200:
        return response.json()
    else:
        raise Exception(f"Gemini API error: {response.status_code} {response.text}")  # Return error if happens


# This Function call a LLM and returns the answer given
def return_prompt(passcode):
    try:

        if active_model == "Groq":  # Seperate by active model
            if not os.environ.get("GROQ_API_KEY"):
                os.environ["GROQ_API_KEY"] = st.secrets["API"]["groqkey"]  # Find groq key in secret file

            model = init_chat_model(
                "llama3-8b-8192",  # Specify model
                model_provider="groq"
            )

            messages = [  # Structure model messages
                SystemMessage(content=(
                    "You are an assistant that helps users reduce stress with actionable, personalized recommendations. "
                    "Respond only with a valid JSON object matching the schema. No markdown, no explanations, no code blocks."
                )),  # Work on tone and model role
                HumanMessage(content=create_prompt(passcode))  # Add generated prompt
            ]

            result = model.invoke(messages)  # Call model to generate recommendation

            return True, result, create_prompt(passcode)  # Return new recommendation

        elif active_model == "Gemini":  # Seperate by active model

            result = call_gemini_api(passcode)  # Call model to generate recommendation

            generated_text = result["candidates"][0]["content"]["parts"][0]["text"]  # Extract only the answer text

            return True, generated_text, create_prompt(passcode)  # Return new recommendation

    except Exception as e:
        print(str(e))  # Print problem with recommendation generation
        return False, str(e), None  # Return problem with recommendation generation


# This function processes a LLM answer and extracts from the JSON request the new recommendation information
def extract_json(new_recommendation, prompt):
    try:
        text = getattr(new_recommendation, "content", str(new_recommendation)).strip()

        if text.startswith(prompt):
            text = text[len(prompt):].strip()

        match = re.search(r'\{[\s\S]*?\}', text)

        if not match:
            return "No JSON Found", text.strip(), 5

        json_str = match.group(0)

        # Attempt regular JSON parse first
        try:
            response_json = json.loads(json_str)
        except json.JSONDecodeError:
            try:
                # Targeted replacement: only keys, not all single quotes
                json_str_fixed = json_str

                # Replace 'Title': with "Title":
                json_str_fixed = re.sub(r"'Title'\s*:", r'"Title":', json_str_fixed)
                json_str_fixed = re.sub(r"'Description'\s*:", r'"Description":', json_str_fixed)
                json_str_fixed = re.sub(r"'Duration'\s*:", r'"Duration":', json_str_fixed)

                # Also replace ': int(' with ': '
                json_str_fixed = re.sub(r": int\(", r": ", json_str_fixed)
                json_str_fixed = json_str_fixed.replace(")", "")

                response_json = json.loads(json_str_fixed)
            except Exception:
                return "Invalid Format", json_str.strip(), 5

        title = response_json.get("Title", "Untitled")
        description = response_json.get("Description", text.strip())
        duration = response_json.get("Duration", 5)

        try:
            duration = int(duration)
        except (ValueError, TypeError):
            duration = 5

        return title, description, duration

    except Exception as e:
        return "Error", f"{str(e)}\n\nRaw Output:\n{str(new_recommendation)}", 5


# This function generates a user profile to be added to a prompt to an AI, and a condition to indicate if it did it correctly
def generate_user_profile(passcode):
    user = User.find_one({"Passcode": passcode})  # Find the user using their Passcode

    # Find the last status the user made (look in the function for more) and make sure we enter the right amount if return variables

    today, yesterday, index = get_status(passcode)

    if not today:  # If the user hasn't made a status, we can't generate a profile for them

        return 'Something went wrong, status was not found'

    status = Status.find_one({"_id": index})

    stress_level = status['Stress_Level']  # Find the status to find the stress level

    data = Recommendation_Per_Person.find({"Passcode": passcode, "Status_Created_At": status['Created_At']})

    previous_recommendations = []

    for entry in data:

        if Recommendation.find_one({"ID": entry['ID']}):
            previous_recommendations.append(
                {
                    'Recommendation': Recommendation.find_one({"ID": entry['ID']})['Description']
                }
            )

    answers = []  # Initialise table
    history = []  # Initialise table

    Question_Questionnaire_list = list(Question_Questionnaire.find())

    for entry in Question_Questionnaire_list:

        if Question.find_one({"Passcode": passcode, "Question": entry['Question']}, sort=[("Created_At", -1)]):
            answers.append(
                # The table will hold the latest answer to a questionnaire question
                {
                    'Question': entry['Question'],
                    'Answer': Question.find_one({"Passcode": passcode, "Question": entry['Question']},
                                                sort=[("Created_At", -1)])['Answer']
                }
            )
            data = list(Question.find({"Passcode": passcode, "Question": entry['Question']}))
            for sub_entry in data:
                history.append(
                    # The table will hold all the answers the user has given, ever
                    {
                        'Question': entry['Question'],
                        'Answers': sub_entry['Answer'],
                        'Created_at': sub_entry['Created_At']
                    }

                )

    data = list(
        Recommendation.find({"Passcode": passcode}))  # Gathering user preferences by checking recommendations we have
    preferences = []  # Initialise table

    for entry in data:

        if Favorite_Recommendation.find({"Passcode": passcode, "ID": entry['ID']}) or Removed_Recommendation.find(
                {"Passcode": passcode,
                 "ID": entry['ID']}):  # We see if it is either category, can be on only one by design

            preferences.append(
                # This table holds the user's preferences
                {
                    'Preference': (
                        'User liked this recommendation' if Favorite_Recommendation.find(
                            {"Passcode": passcode, "ID": entry['ID']}) is not None
                        else "User didn't like this recommendation"
                    ),
                    'Recommendation': entry['Description']
                }

            )

    data = list(Question.find({"Passcode": passcode, "Question": con_question}))
    confessions = []  # Initialise table

    for entry in data:
        confessions.append(
            {
                'entry': entry['Answer']
            }
        )

    my_prompt = (
        f"User between the ages of {user['Age_Category']} has answered various questions about his experience with stress today. The questions and answers are in the table given here: {answers}."
        f"Based on his answers today we rated their stress level as {stress_level}. The Users gender is defined by him as {user['Gender']}"
        f"The user has identified {user['Focus_Area']} as the area mostly stressing them out, and has {user['Time_Available']} minutes free to do an activity today."
        f"Additionally we also have the user's answers to the stress related questions in the past in this table: {history}"
        f"We are also provided with the user's general thoughts, be aware this might be empty as the user might be new: {confessions}"
        f"Lastly we have a collection of the user has seen and has given feedback back, we have that information here: {preferences}"
        f"The user has already been given today the recommendations {previous_recommendations}. Please don't return any similar.")

    return my_prompt
